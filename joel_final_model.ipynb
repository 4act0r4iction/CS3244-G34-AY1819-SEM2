{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "#sklearn imports\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import log_loss, recall_score, precision_score, f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('features_and_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(\"is_fake\", axis = 1), df.is_fake\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y = df.iloc[:,:-7], df.is_fake\n",
    "\n",
    "X2_train, X2_val, y_train, y_val = train_test_split(X2, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('std_scaler', StandardScaler()),\n",
    "                     ('xgb', xgb.XGBClassifier())\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'xgb__learning_rate':[0.01,0.015,0.025,0.05,0.1],\n",
    "    'xgb__gamma':[0.05,0.1,0.3,0.5,0.7,0.9,1.0],\n",
    "    'xgb__max_depth':[3,5,7,9,12,15,17,25],\n",
    "    'xgb__min_child_weight':[1,3,5,7],\n",
    "    'xgb__subsample':[0.6,0.7,0.8,0.9,1.0],\n",
    "    'xgb__reg_lambda':[0.01,0.05,0.1,1.0],\n",
    "    'xgb__reg_alpha':[0,0.1,0.5,1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model with only the manual features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:  6.2min\n",
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=10)]: Done 1780 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=10)]: Done 2430 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=10)]: Done 3000 out of 3000 | elapsed: 24.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1460.838391304016"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "xgb_model = RandomizedSearchCV(pipeline, param, cv=3,verbose=1, n_iter = 1000, n_jobs = 10)\n",
    "#fit model\n",
    "xgb_model.fit(X2_train,y_train)\n",
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for xgb: 0.9732121502033007\n",
      "Val accuracy for xgb: 0.7908163265306123\n",
      "Val precision for xgb: 0.8124428179322964\n",
      "Val recall for xgb: 0.8783382789317508\n",
      "f1_score for xgb: 0.844106463878327\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_xgb = xgb_model.predict(X2_val)\n",
    "y_all_pred_xgb = xgb_model.predict(X2)\n",
    "\n",
    "print(\"Train accuracy for xgb: \" + str(xgb_model.score(X2_train, y_train)))\n",
    "print(\"Val accuracy for xgb: \" + str(xgb_model.score(X2_val, y_val)))\n",
    "print(\"Val precision for xgb: \" + str(precision_score(y_val, y_val_pred_xgb)))\n",
    "print(\"Val recall for xgb: \" + str(recall_score(y_val, y_val_pred_xgb)))\n",
    "print(\"f1_score for xgb: \" + str(f1_score(y_val, y_val_pred_xgb))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68      1114\n",
      "           1       0.81      0.88      0.84      2022\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      3136\n",
      "   macro avg       0.78      0.76      0.76      3136\n",
      "weighted avg       0.79      0.79      0.79      3136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_val_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   9 out of   9 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('std_scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=10,\n",
       "       param_grid={'lr__C': (0.01, 0.1, 1)}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring=None, verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pipeline = Pipeline([('std_scaler', StandardScaler()),\n",
    "                     ('lr', LogisticRegression(solver = 'liblinear'))\n",
    "                    ])\n",
    "\n",
    "logreg_parameters = {'lr__C': (0.01, 0.1, 1),\n",
    "             }\n",
    "\n",
    "logreg_model = GridSearchCV(logreg_pipeline, logreg_parameters, n_jobs = 10, verbose = 1, cv = 3)\n",
    "logreg_model.fit(X2_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for logreg: 0.691301921390417\n",
      "Val accuracy for logreg: 0.6935586734693877\n",
      "Val precision for logreg: 0.7008708822415751\n",
      "Val recall for logreg: 0.9154302670623146\n",
      "f1_score for logreg: 0.7933113800624386\n"
     ]
    }
   ],
   "source": [
    "y_pred_logreg = logreg_model.predict(X2_val)\n",
    "y_all_pred_logreg = logreg_model.predict(X2)\n",
    "\n",
    "print(\"Train accuracy for logreg: \" + str(logreg_model.score(X2_train, y_train)))\n",
    "print(\"Val accuracy for logreg: \" + str(logreg_model.score(X2_val, y_val)))\n",
    "print(\"Val precision for logreg: \" + str(precision_score(y_val, y_pred_logreg)))\n",
    "print(\"Val recall for logreg: \" + str(recall_score(y_val, y_pred_logreg)))\n",
    "print(\"f1_score for logreg: \" + str(f1_score(y, y_all_pred_logreg))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
