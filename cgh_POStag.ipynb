{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "#sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import log_loss, recall_score, precision_score\n",
    "\n",
    "from lib.processor import *\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In an interview with congressional investigato...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Getty - John Shearer / Staff \\nComedian Patton...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By Jameson Parker Election 2016 , Politics Nov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last updated at 16:53 GMT A helmet for cyclis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13 Herbal Teas With Highest Antioxidants http:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  In an interview with congressional investigato...      0\n",
       "1  Getty - John Shearer / Staff \\nComedian Patton...      1\n",
       "2  By Jameson Parker Election 2016 , Politics Nov...      1\n",
       "3   Last updated at 16:53 GMT A helmet for cyclis...      0\n",
       "4  13 Herbal Teas With Highest Antioxidants http:...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def pre_process(raw_text): #pre-processes the raw text from the dataset\n",
    "    ex = preprocess_text(raw_text, remove_special = False, stem=False, lemmatize = False, remove_stops = False)\n",
    "    ex = ex.replace(\"\\n\", \"\")\n",
    "    ex = ex.replace(\"\\r\", \"\")\n",
    "    doc = nlp(ex)\n",
    "    return doc\n",
    "\n",
    "def get_pos_and_tag(text):\n",
    "    tag_arr = np.zeros(0)\n",
    "    pos_arr = np.zeros(0)\n",
    "    for i in text:\n",
    "        pos_arr = np.append(pos_arr, i.pos_)\n",
    "        tag_arr = np.append(tag_arr, i.tag_)        \n",
    "    return (pos_arr, tag_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function to extract features\n",
    "def get_features(raw_text): #raw_text is original text   \n",
    "    text = pre_process(raw_text)\n",
    "    words = [token.text for token in text if token.is_punct != True]\n",
    "    word_counter = Counter(([word for word in words]))\n",
    "    sorted_word_counts = list(sorted(word_counter.values(), reverse = True)) #sorted in descending order\n",
    "    \n",
    "    pos_arr, tag_arr = get_pos_and_tag(text)\n",
    "    pos_counter = Counter(([pos for pos in pos_arr]))\n",
    "    tag_counter = Counter(([tag for tag in tag_arr]))\n",
    "\n",
    "    total_count = sum(tag_counter.values()) #same for tag and pos\n",
    "    \n",
    "    ###features\n",
    "    total_word_count = sum(word_counter.values())\n",
    "    \n",
    "    if total_word_count == 0:\n",
    "        avg_word_length = 0\n",
    "        lexical_diversity = 0\n",
    "        repetition_top = 0\n",
    "        repetition_all = 0\n",
    "    else:\n",
    "        avg_word_length = sum(len(word) for word in words)/total_word_count\n",
    "        lexical_diversity = len(word_counter)/total_word_count\n",
    "        #sum of number of words of top 20 words seen over total number of words\n",
    "        repetition_top = sum(sorted_word_counts[:20])/total_word_count\n",
    "        #1/k weighting on sum of word counts over total number of words\n",
    "        repetition_all = sum(sorted_word_counts[i]/(i+1) for i in range(len(sorted_word_counts)))/total_word_count\n",
    "    \n",
    "    if total_count == 0:\n",
    "        NNP_percent = 0\n",
    "        NNPS_percent = 0\n",
    "        noun_percent = 0\n",
    "        verb_percent = 0\n",
    "        part_percent = 0\n",
    "        det_percent = 0\n",
    "        unknown_or_foreign_percent = 0\n",
    "    else:\n",
    "        #tag percents\n",
    "        NNP_percent = tag_counter.get(\"NNP\", 0)/total_count\n",
    "        NNPS_percent = tag_counter.get(\"NNPS\", 0)/total_count\n",
    "        #POS percents\n",
    "        noun_percent = pos_counter.get(\"NOUN\", 0)/total_count\n",
    "        verb_percent = pos_counter.get(\"VERB\", 0)/total_count\n",
    "        part_percent = pos_counter.get(\"PART\", 0)/total_count\n",
    "        det_percent = pos_counter.get(\"DET\", 0)/total_count\n",
    "        unknown_or_foreign_percent = pos_counter.get(\"X\", 0)/total_count\n",
    "        \n",
    "    return [total_word_count,avg_word_length,lexical_diversity,repetition_top,repetition_all,\\\n",
    "            NNP_percent,NNPS_percent,noun_percent,verb_percent,part_percent,det_percent,unknown_or_foreign_percent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code block below is the code that takes time. It is much faster (about 20x speed) than the PCFG code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {} #initialize an empty dictionary\n",
    "\n",
    "#THIS IS THE TIME-CONSUMING BLOCK \n",
    "dct['total_word_count'],dct['avg_word_length'],dct['lexical_diversity'],dct['repetition_top'],\\\n",
    "dct['repetition_all'],dct['NNP_percent'],dct['NNPS_percent'],dct['noun_percent'],\\\n",
    "dct['verb_percent'],dct['part_percent'],dct['det_percent'],dct['unknown_or_foreign_percent']\\\n",
    "= zip(*data.iloc[0:0].text.apply(get_features)) #change indices in iloc to match how much data you want to apply onto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pandas df from the dct dictionary (which contains all the extracted features)\n",
    "new_df = pd.DataFrame(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5679, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just to check if output is correct (should be a k x 12 df where k is the number of rows in the iloc)\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>repetition_top</th>\n",
       "      <th>repetition_all</th>\n",
       "      <th>NNP_percent</th>\n",
       "      <th>NNPS_percent</th>\n",
       "      <th>noun_percent</th>\n",
       "      <th>verb_percent</th>\n",
       "      <th>part_percent</th>\n",
       "      <th>det_percent</th>\n",
       "      <th>unknown_or_foreign_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.292897</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2465</td>\n",
       "      <td>4.956592</td>\n",
       "      <td>0.382556</td>\n",
       "      <td>0.345233</td>\n",
       "      <td>0.139596</td>\n",
       "      <td>0.099549</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.182569</td>\n",
       "      <td>0.126972</td>\n",
       "      <td>0.019534</td>\n",
       "      <td>0.131104</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>345</td>\n",
       "      <td>4.162319</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.382609</td>\n",
       "      <td>0.119176</td>\n",
       "      <td>0.049351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166234</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.031169</td>\n",
       "      <td>0.098701</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>932</td>\n",
       "      <td>5.101931</td>\n",
       "      <td>0.443133</td>\n",
       "      <td>0.335837</td>\n",
       "      <td>0.136687</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.201951</td>\n",
       "      <td>0.149268</td>\n",
       "      <td>0.018537</td>\n",
       "      <td>0.126829</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>569</td>\n",
       "      <td>4.889279</td>\n",
       "      <td>0.562390</td>\n",
       "      <td>0.328647</td>\n",
       "      <td>0.110294</td>\n",
       "      <td>0.135937</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.151562</td>\n",
       "      <td>0.151562</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_word_count  avg_word_length  lexical_diversity  repetition_top  \\\n",
       "0                10         5.200000           1.000000        1.000000   \n",
       "1              2465         4.956592           0.382556        0.345233   \n",
       "2               345         4.162319           0.565217        0.382609   \n",
       "3               932         5.101931           0.443133        0.335837   \n",
       "4               569         4.889279           0.562390        0.328647   \n",
       "\n",
       "   repetition_all  NNP_percent  NNPS_percent  noun_percent  verb_percent  \\\n",
       "0        0.292897     0.545455      0.000000      0.090909      0.000000   \n",
       "1        0.139596     0.099549      0.006386      0.182569      0.126972   \n",
       "2        0.119176     0.049351      0.000000      0.166234      0.207792   \n",
       "3        0.136687     0.120000      0.002927      0.201951      0.149268   \n",
       "4        0.110294     0.135937      0.009375      0.151562      0.151562   \n",
       "\n",
       "   part_percent  det_percent  unknown_or_foreign_percent  \n",
       "0      0.000000     0.090909                    0.000000  \n",
       "1      0.019534     0.131104                    0.000751  \n",
       "2      0.031169     0.098701                    0.000000  \n",
       "3      0.018537     0.126829                    0.000000  \n",
       "4      0.025000     0.118750                    0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just checking\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv, rename as desired\n",
    "new_df.to_csv(\"postag_output_aaa.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  @whoever is compiling the codes, can ignore all code chunks below this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### noun percents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "1606\n",
      "0.0896637608966376\n"
     ]
    }
   ],
   "source": [
    "def NNP_percent(postag_count):\n",
    "    return postag_count.get(\"NNP\") / sum(postag_count.values())\n",
    "\n",
    "def NNPS_percent(postag_count):\n",
    "    return postag_count.get(\"NNPS\") / sum(postag_count.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General version (postag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postag_percent(postag_count, postag_string):\n",
    "    return postag_count.get(postag_string) / sum(postag_count.values())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verb count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_postag(doc):\n",
    "    pos_arr = np.zeros(0)\n",
    "    for i in doc:\n",
    "        pos_arr = np.append(postag_arr, i.pos_)\n",
    "    \n",
    "    return pos_arr\n",
    "    \n",
    "\n",
    "def verb_count(pos_arr):\n",
    "    pos_count = Counter(([pos for pos in pos_arr]))\n",
    "    verb_count = pos_count.get(\"VERB\") / sum(pos_count.values())\n",
    "    # print(pos_count)\n",
    "    # print(pos_count.get(\"VERB\"))\n",
    "    # print(sum(pos_count.values()))\n",
    "    # print(verb_count)\n",
    "    \n",
    "    return verb_count\n",
    "\n",
    "#(ver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NOUN', 'NOUN', 'PROPN', ..., 'ADJ', 'NOUN', 'PUNCT'], dtype='<U32')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General version (pos) (less powerful version of postag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_count(pos_arr, pos_string):\n",
    "    pos_count = Counter(([pos for pos in pos_arr]))\n",
    "    result = pos_count.get(pos_string) / sum(pos_count.values())\n",
    "    # print(pos_count)\n",
    "    # print(pos_count.get(\"VERB\"))\n",
    "    # print(sum(pos_count.values()))\n",
    "    # print(verb_count)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Word Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.136521136521137\n"
     ]
    }
   ],
   "source": [
    "# token.is_stop != True\n",
    "words =  [token.text for token in doc if token.is_punct != True]\n",
    "# print(words)\n",
    "\n",
    "def average_word_length(words):\n",
    "    count = 0\n",
    "    \n",
    "    for word in words:     \n",
    "        count += len(word)\n",
    "        \n",
    "    return count / len(words)\n",
    "\n",
    "# print(words)\n",
    "print(average_word_length(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.137777777777778\n"
     ]
    }
   ],
   "source": [
    "def average_word_count(word_counter):\n",
    "    # print(word_counter.values())\n",
    "    return np.array(list(word_counter.values())).mean()\n",
    "\n",
    "# print(words)\n",
    "print(average_word_count(word_counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1443\n"
     ]
    }
   ],
   "source": [
    "def word_count(word_counter):\n",
    "    return sum(word_counter.values())\n",
    "\n",
    "# print(word_count(words))\n",
    "print(sum(word_counter.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686\n"
     ]
    }
   ],
   "source": [
    "def unique_words(word_counter):\n",
    "    return len(word_counter)\n",
    "\n",
    "print(unique_words(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(word_counter):\n",
    "    return unique_words(word_counter) / word_count(word_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.sents)\n",
    "\n",
    "def sentence_count(doc):\n",
    "    return len(list(doc.sents))\n",
    "\n",
    "sentence_count(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6ab5fcfe59bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "doc.sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data.text, data.label\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, \n",
    "                                                  stratify=y, \n",
    "                                                  random_state=0, \n",
    "                                                  test_size=0.1, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27208,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30232,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "postag_arr = np.zeros(0)\n",
    "for i in doc:\n",
    "    postag_arr = np.append(postag_arr, i.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NN', 'NN', 'NNP', ..., 'JJ', 'NN', '.'], dtype='<U32')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postag_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
